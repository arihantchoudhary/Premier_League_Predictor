{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07564c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "save_initial = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27268c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aggregate all seasons into one directory\n",
    "if save_initial:\n",
    "    input_paths    = [f\"./data/20{i}-{i+1}/players/\" for i in range(16, 23)]\n",
    "    init_path      = \"./data/2023-24/players/\"\n",
    "    save_path      = \"./data/2016-24/\"\n",
    "    for i in os.listdir(init_path):\n",
    "        if i[0] == '.':\n",
    "            continue\n",
    "        df         = pd.read_csv(os.path.join(init_path, i, \"gw.csv\"))\n",
    "        for j in input_paths:\n",
    "            for k in os.listdir(j):\n",
    "                if k.split(\"_\")[:-1] != i.split(\"_\")[:-1]:\n",
    "                    continue\n",
    "                d2 = pd.read_csv(os.path.join(j, k, \"gw.csv\"))\n",
    "                df = pd.concat([df, d2], ignore_index=True)\n",
    "        df.to_csv(os.path.join(save_path, f'{\"_\".join(i.split(\"_\")[:-1])}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5594c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make cummulative frequency curve of games listed per player\n",
    "# Figure out what columns are not present in all dfs\n",
    "\n",
    "if save_initial:\n",
    "    dfs            = []\n",
    "    cols           = set()\n",
    "    not_all        = set()\n",
    "    for i in os.listdir(save_path):\n",
    "        dfs       += [pd.read_csv(os.path.join(save_path, i))]\n",
    "        cols       = cols.union(set(dfs[-1].columns))\n",
    "        not_all    = not_all.union(set(cols).difference(set(dfs[-1].columns)))\n",
    "\n",
    "    numGames       = [len(i) for i in dfs]\n",
    "    total          = max(numGames)\n",
    "    freq           = [0] * (total + 1)\n",
    "    for i in numGames:\n",
    "        freq[i]   += 1\n",
    "    temp           = 0\n",
    "    for i in range(len(frequency) - 1, -1, -1):\n",
    "        freq[i]   += temp\n",
    "        temp       = freq[i]\n",
    "    plt.plot(range(len(freq)), freq)\n",
    "\n",
    "    print(not_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a0fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assists', 'bonus', 'bps', 'clean_sheets', 'goals_conceded', 'goals_scored', 'minutes', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'round', 'saves', 'selected', 'total_points', 'transfers_in', 'transfers_out', 'value', 'yellow_cards']\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset: \n",
    "    #    train.csv containing (nx5m values), where each row is a flattened stat summary from past 5 games for one player\n",
    "    #    labels.csv containing (nx1) values, total points in next game for each player\n",
    "    \n",
    "not_all      = {'target_missed', 'fouls', 'recoveries', 'key_passes', \n",
    "                'clearances_blocks_interceptions', 'big_chances_created', \n",
    "                'errors_leading_to_goal_attempt', 'completed_passes', 'tackled', \n",
    "                'kickoff_time_formatted', 'attempted_passes', 'tackles', 'offside', \n",
    "                'big_chances_missed', 'loaned_in', 'errors_leading_to_goal', 'penalties_conceded', \n",
    "                'loaned_out', 'winning_goals', 'open_play_crosses', 'dribbles', 'id', 'ea_index'}\n",
    "columnNames  = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity', 'element',\n",
    "                'expected_assists', 'expected_goal_involvements', 'expected_goals',\n",
    "                'expected_goals_conceded', 'fixture', 'goals_conceded', 'goals_scored',\n",
    "                'ict_index', 'influence', 'kickoff_time', 'minutes', 'opponent_team',\n",
    "                'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards',\n",
    "                'round', 'saves', 'selected', 'starts', 'team_a_score', 'team_h_score',\n",
    "                'threat', 'total_points', 'transfers_balance', 'transfers_in',\n",
    "                'transfers_out', 'value', 'was_home', 'yellow_cards',\n",
    "                'attempted_passes', 'big_chances_created', 'big_chances_missed',\n",
    "                'clearances_blocks_interceptions', 'completed_passes', 'dribbles',\n",
    "                'ea_index', 'errors_leading_to_goal', 'errors_leading_to_goal_attempt',\n",
    "                'fouls', 'id', 'key_passes', 'kickoff_time_formatted', 'loaned_in',\n",
    "                'loaned_out', 'offside', 'open_play_crosses', 'penalties_conceded',\n",
    "                'recoveries', 'tackled', 'tackles', 'target_missed', 'winning_goals']\n",
    "drop_columns = {'kickoff_time', 'transfers_balance', 'fixture', 'creativity', 'element',\n",
    "                'expected_assists', 'expected_goal_involvements', 'expected_goals',\n",
    "                'fixture', 'ict_index', 'influence', 'starts', 'team_a_score', \n",
    "                'threat', 'team_h_score', 'expected_goals_conceded', 'opponent_team', 'was_home'}.union(not_all)\n",
    "\n",
    "columnNames  = [i for i in columnNames if i not in drop_columns]\n",
    "print(columnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1290b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assists             0\n",
      "bonus               0\n",
      "bps                 0\n",
      "clean_sheets        0\n",
      "goals_conceded      0\n",
      "goals_scored        0\n",
      "minutes             0\n",
      "own_goals           0\n",
      "penalties_missed    0\n",
      "penalties_saved     0\n",
      "red_cards           0\n",
      "round               0\n",
      "saves               0\n",
      "selected            0\n",
      "total_points        0\n",
      "transfers_in        0\n",
      "transfers_out       0\n",
      "value               0\n",
      "yellow_cards        0\n",
      "dtype: int64\n",
      "{'assists': 0.047924781349427154, 'bonus': 0.12616815762815847, 'bps': 6.874973248298592, 'clean_sheets': 0.11929118691948808, 'goals_conceded': 0.5609154075532538, 'goals_scored': 0.05170568848178744, 'minutes': 36.758507041047814, 'own_goals': 0.001940390075475467, 'penalties_missed': 0.000955927463653355, 'penalties_saved': 0.0006848435560501648, 'red_cards': 0.0020259955199817374, 'round': 18.842100757608183, 'saves': 0.120004565623707, 'selected': 258238.08733182098, 'total_points': 1.5686056299847337, 'transfers_in': 18494.909957339954, 'transfers_out': 16673.734979811383, 'value': 51.24817018362368, 'yellow_cards': 0.06339083165689338}\n",
      "{'assists': 0.2338256160536145, 'bonus': 0.5278362463199091, 'bps': 10.183292926967075, 'clean_sheets': 0.32413314953419525, 'goals_conceded': 1.003206334338034, 'goals_scored': 0.24609200349270924, 'minutes': 41.34908511136727, 'own_goals': 0.04400741520658549, 'penalties_missed': 0.030903515855970717, 'penalties_saved': 0.026700559266795345, 'red_cards': 0.04496576153056908, 'round': 11.160710500107147, 'saves': 0.7028124562667061, 'selected': 650376.4721286546, 'total_points': 2.6787228057726202, 'transfers_in': 66200.51432597749, 'transfers_out': 59056.58984400398, 'value': 12.5763524347747, 'yellow_cards': 0.2436663317560089}\n"
     ]
    }
   ],
   "source": [
    "# NaN analysis\n",
    "input_path       = \"./data/2016-24/\"\n",
    "dfs              = [pd.read_csv(os.path.join(input_path, i)).loc[:, columnNames] \n",
    "                    for i in os.listdir(input_path)\n",
    "                    if i[0] != \".\"]\n",
    "megaDf           = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "counts           = megaDf.isna().sum()\n",
    "print(counts)\n",
    "# Insert NaN handling if NaNs\n",
    "\n",
    "# Normalization\n",
    "save_path        = \"./data/2016-24_processed/\"\n",
    "means            = {col:count for col, count in megaDf.mean().items()}\n",
    "sds              = {col:count for col, count in megaDf.std().items()}\n",
    "print(means)\n",
    "print(sds)\n",
    "\n",
    "# Don't normalize total_points\n",
    "means['total_points'] = 0\n",
    "sds['total_points'] = 1\n",
    "\n",
    "for name, df in zip(os.listdir(input_path), dfs):\n",
    "    for col, mean in means.items():\n",
    "        df[col] -= mean\n",
    "        df[col] /= sds[col]\n",
    "    df.to_csv(os.path.join(save_path, name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce805946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 812/812 [00:14<00:00, 56.88it/s]\n"
     ]
    }
   ],
   "source": [
    "trainColumns   = []\n",
    "for j in [\"_1\", \"_2\", \"_3\", \"_4\", \"_5\"]: # 5 games\n",
    "    trainColumns += [i+j for i in columnNames]\n",
    "\n",
    "train          = []\n",
    "labels         = []\n",
    "\n",
    "input_path     = \"./data/2016-24_processed/\"\n",
    "for i in tqdm(os.listdir(input_path)):\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    curr_path  = os.path.join(input_path, i)\n",
    "    df         = pd.read_csv(curr_path)\n",
    "    for label_row in range(5, len(df)):\n",
    "        vector = df.iloc[label_row - 5:label_row].values.flatten()\n",
    "        label  = df['total_points'].iloc[label_row]\n",
    "        train += [pd.Series(vector, index = trainColumns)]\n",
    "        labels+= [pd.Series([label], index = [\"Points\"])]\n",
    "        \n",
    "train          = pd.concat(train, ignore_index = True)\n",
    "labels         = pd.concat(labels, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c41f9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path      = \"./train_2016-24/\"\n",
    "train.to_csv(os.path.join(save_path, 'inputs.csv'), index=False)\n",
    "labels.to_csv(os.path.join(save_path, 'labels.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
